## 一页梳理版：用大模型 API 处理批量任务

### 0. 前言要点

* 场景：产品调研收集到 **1 万+** 主观反馈，未结构化
* 目标：在 **1 天内**统计出主要待改进点（价格、售后、体验等）
* 痛点：人工阅读或单次大模型分析适用于小样本，面对海量文本不可扩展
* 解法：用 **大模型服务 API** 做批处理，将“非结构化文本”变为“结构化分类结果”

---

## 课程目标

* 理解：如何借助大模型服务 API 自动处理一批任务
* 迁移：识别业务中可用 API 提效的机会点

---

## 1. 借助通义千问 API 自动完成批量文本处理

### 1.1 需求与难点拆解

* 输入：大量主观反馈（自由文本）
* 输出：按原因分类的结构化结果
* 约束：时限短、规模大
* 关键技术动作：

  * 统一分类体系（label set）
  * 设计稳定的输出格式（便于后处理）
  * 通过程序循环调用模型

### 1.2 最小可用调用范式（单条分类）

* 工具：`langchain_community.llms.Tongyi`
* 模型：示例使用 `qwen-max`，也可替换为其他可用模型
* 核心提示词要素：

  1. **任务**：原因分类
  2. **标签集合**：价格过高、售后支持不足、产品使用体验不佳、其他
  3. **输出格式**：固定字段，如“分类结果：xx”
  4. **输入文本**：用户反馈原文

> 关键点：固定输出格式，后续才能稳定写入 Excel 或做统计。

### 1.3 批处理范式（从 Excel 读入逐行分类）

* 输入载体：Excel 文件（openpyxl 读取）
* 处理方式：遍历行 → 调用模型 → 输出分类结果
* 产出形式：示例是 `print`，实际可写回 Excel 新列或写入 CSV

你这段示例代码本质上做了三件事：

1. 读数据：逐行拿到 feedback
2. 调用模型：把 feedback 拼进统一 prompt
3. 输出结果：打印，便于观察和调试

---

## 1.4 运行前置条件（工程化准备）

* 开通：阿里云百炼
* 获取：API Key（用于调用通义千问 API）
* 配置：把 API Key 配到环境变量或代码配置
* 安装依赖：`langchain_community` 与 `dashscope`，批处理还需要 `openpyxl`

> 这里的教学策略是用 LangChain 降低样板代码量，帮助非工程读者理解流程。

---

## 1.5 无编程基础的替代路径：通义灵码

定位：把“自然语言需求”转成可运行代码

演示流程可抽象为：

1. 用函数计算 FC 模板快速创建运行环境
2. 在线 IDE 中安装依赖（requirements）
3. 给通义灵码输入需求提示词
4. 提供参考代码以提高命中率（因为训练数据时效性问题）
5. 替换为自己的 API Key 并运行
6. 若失败，迭代提示词与代码

本段的核心价值：把“不会写代码”转换成“会描述需求并能迭代提示词”。

---

## 1.6 团队协作落点

* 若有工程团队：你可以把需求与实现建议直接交给技术同事
* 若想自学：材料提到有入门级 API 教程可继续补齐运行能力

---

## 2. 阿里云上大模型服务 API 调用要点

### 2.1 计费与选型逻辑

* 形态：按量付费、开箱即用
* 取舍：

  * 小参数模型：更快、更省，适合简单分类与抽取
  * 大参数模型：更强，适合复杂推理与高难度场景
* 实操建议：先用小模型跑通流程，再用大模型处理难例或做抽样复核

### 2.2 多模态扩展

* 提到通义千问 VL：可做视觉理解，如拍照改作业等

---

## 本节小结的关键迁移点

* 用 API 把大模型能力嵌入程序流程，实现“批量自动化”
* 不止文本：可与其他模型组合形成更复杂流水线

  * 示例：语音转文字（ASR）→ 大语言模型做质检与归因
* 方法论：找到业务里高频、规则不清、文本密集的环节，把“人工理解”变成“结构化输出”

---

## 你可以补强的一页“实战检查清单”

* 分类体系是否互斥且覆盖全面
* 输出格式是否稳定且可解析
* 是否做了失败重试与异常处理
* 是否做了抽样人工复核与一致性评估
* 是否考虑成本控制与并发吞吐
* 是否把结果落到可统计的数据结构（表格或数据库）

如果你下一节要继续写“如何优化提示词提升批处理质量”，建议围绕：标签定义、示例驱动、输出约束、置信度与拒答策略、难例回流这五个点展开。